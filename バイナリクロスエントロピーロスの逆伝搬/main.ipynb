{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "予測ラベル(y_hat_1): 0.498 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.806 正解ラベル(y_2): 0\n",
      "\n",
      "\n",
      "epoch: 2\n",
      "予測ラベル(y_hat_1): 0.506 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.781 正解ラベル(y_2): 0\n",
      "\n",
      "\n",
      "epoch: 3\n",
      "予測ラベル(y_hat_1): 0.524 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.726 正解ラベル(y_2): 0\n",
      "\n",
      "\n",
      "epoch: 4\n",
      "予測ラベル(y_hat_1): 0.550 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.631 正解ラベル(y_2): 0\n",
      "\n",
      "\n",
      "epoch: 5\n",
      "予測ラベル(y_hat_1): 0.585 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.497 正解ラベル(y_2): 0\n",
      "\n",
      "\n",
      "epoch: 6\n",
      "予測ラベル(y_hat_1): 0.629 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.344 正解ラベル(y_2): 0\n",
      "\n",
      "\n",
      "epoch: 7\n",
      "予測ラベル(y_hat_1): 0.680 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.208 正解ラベル(y_2): 0\n",
      "\n",
      "\n",
      "epoch: 8\n",
      "予測ラベル(y_hat_1): 0.736 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.114 正解ラベル(y_2): 0\n",
      "\n",
      "\n",
      "epoch: 9\n",
      "予測ラベル(y_hat_1): 0.792 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.059 正解ラベル(y_2): 0\n",
      "\n",
      "\n",
      "epoch: 10\n",
      "予測ラベル(y_hat_1): 0.843 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.029 正解ラベル(y_2): 0\n",
      "\n",
      "\n",
      "epoch: 11\n",
      "予測ラベル(y_hat_1): 0.886 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.015 正解ラベル(y_2): 0\n",
      "\n",
      "\n",
      "epoch: 12\n",
      "予測ラベル(y_hat_1): 0.920 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.007 正解ラベル(y_2): 0\n",
      "\n",
      "\n",
      "epoch: 13\n",
      "予測ラベル(y_hat_1): 0.945 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.004 正解ラベル(y_2): 0\n",
      "\n",
      "\n",
      "epoch: 14\n",
      "予測ラベル(y_hat_1): 0.963 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.002 正解ラベル(y_2): 0\n",
      "\n",
      "\n",
      "epoch: 15\n",
      "予測ラベル(y_hat_1): 0.976 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.001 正解ラベル(y_2): 0\n",
      "\n",
      "\n",
      "epoch: 16\n",
      "予測ラベル(y_hat_1): 0.984 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.000 正解ラベル(y_2): 0\n",
      "\n",
      "\n",
      "epoch: 17\n",
      "予測ラベル(y_hat_1): 0.989 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.000 正解ラベル(y_2): 0\n",
      "\n",
      "\n",
      "epoch: 18\n",
      "予測ラベル(y_hat_1): 0.993 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.000 正解ラベル(y_2): 0\n",
      "\n",
      "\n",
      "epoch: 19\n",
      "予測ラベル(y_hat_1): 0.996 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.000 正解ラベル(y_2): 0\n",
      "\n",
      "\n",
      "epoch: 20\n",
      "予測ラベル(y_hat_1): 0.997 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.000 正解ラベル(y_2): 0\n",
      "\n",
      "\n",
      "epoch: 21\n",
      "予測ラベル(y_hat_1): 0.998 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.000 正解ラベル(y_2): 0\n",
      "\n",
      "\n",
      "epoch: 22\n",
      "予測ラベル(y_hat_1): 0.999 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.000 正解ラベル(y_2): 0\n",
      "\n",
      "\n",
      "epoch: 23\n",
      "予測ラベル(y_hat_1): 0.999 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.000 正解ラベル(y_2): 0\n",
      "\n",
      "\n",
      "epoch: 24\n",
      "予測ラベル(y_hat_1): 0.999 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.000 正解ラベル(y_2): 0\n",
      "\n",
      "\n",
      "epoch: 25\n",
      "予測ラベル(y_hat_1): 1.000 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.000 正解ラベル(y_2): 0\n",
      "\n",
      "\n",
      "epoch: 26\n",
      "予測ラベル(y_hat_1): 1.000 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.000 正解ラベル(y_2): 0\n",
      "\n",
      "\n",
      "epoch: 27\n",
      "予測ラベル(y_hat_1): 1.000 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.000 正解ラベル(y_2): 0\n",
      "\n",
      "\n",
      "epoch: 28\n",
      "予測ラベル(y_hat_1): 1.000 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.000 正解ラベル(y_2): 0\n",
      "\n",
      "\n",
      "epoch: 29\n",
      "予測ラベル(y_hat_1): 1.000 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.000 正解ラベル(y_2): 0\n",
      "\n",
      "\n",
      "epoch: 30\n",
      "予測ラベル(y_hat_1): 1.000 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.000 正解ラベル(y_2): 0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(42)\n",
    "# torch.manual_seed(5)\n",
    "\n",
    "# 入力特徴量\n",
    "x_1 = torch.tensor([0.1, 0.5, -0.2, 1.2, 0.3])\n",
    "x_2 = torch.tensor([0.7, -0.2, -0.4, 0.8, -1.0])\n",
    "\n",
    "# 正解ラベル\n",
    "y_1 = 1 \n",
    "y_2 = 0\n",
    "\n",
    "# 重み行列Wを初期化\n",
    "W = torch.randn(1, 5, requires_grad=True) # 1x5次元\n",
    "\n",
    "epoch = 30\n",
    "# learning_rate = 0.1\n",
    "learning_rate = 0.1\n",
    "\n",
    "for i in range(epoch):\n",
    "    \n",
    "    print(f\"epoch: {i+1}\")\n",
    "\n",
    "    ### 順伝播 ###\n",
    "    \n",
    "    o_1 = W @ x_1\n",
    "    o_2 = W @ x_2\n",
    "    \n",
    "    y_hat_1 = torch.sigmoid(o_1)\n",
    "    y_hat_2 = torch.sigmoid(o_2)\n",
    "\n",
    "    print('予測ラベル(y_hat_1):', f'{y_hat_1.item():0.3f}', '正解ラベル(y_1):', y_1)\n",
    "    print('予測ラベル(y_hat_2):', f'{y_hat_2.item():0.3f}', '正解ラベル(y_2):', y_2)\n",
    "        \n",
    "\n",
    "    ### 逆伝播 ###\n",
    "\n",
    "    # バイナリクロスエントロピーロス\n",
    "    loss_1 = -(y_1 * torch.log(y_hat_1) + (1 - y_1) * torch.log(1 - y_hat_1))\n",
    "    loss_2 = - (y_2 * torch.log(y_hat_2) + (1 - y_2) * torch.log(1 - y_hat_2))\n",
    "    \n",
    "    loss = loss_1 + loss_2\n",
    "    loss.backward() # W.gradに勾配が入る\n",
    "    \n",
    "    # 勾配を使ってパラメータを更新\n",
    "    with torch.no_grad():\n",
    "        W -= learning_rate * W.grad\n",
    "\n",
    "    # 勾配の初期化\n",
    "    W.grad.zero_()\n",
    "    \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "予測ラベル(y_hat_1): 0.498 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.806 正解ラベル(y_2): 0\n",
      "\n",
      "epoch: 2\n",
      "予測ラベル(y_hat_1): 0.506 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.781 正解ラベル(y_2): 0\n",
      "\n",
      "epoch: 3\n",
      "予測ラベル(y_hat_1): 0.515 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.755 正解ラベル(y_2): 0\n",
      "\n",
      "epoch: 4\n",
      "予測ラベル(y_hat_1): 0.524 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.728 正解ラベル(y_2): 0\n",
      "\n",
      "epoch: 5\n",
      "予測ラベル(y_hat_1): 0.533 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.700 正解ラベル(y_2): 0\n",
      "\n",
      "epoch: 6\n",
      "予測ラベル(y_hat_1): 0.542 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.672 正解ラベル(y_2): 0\n",
      "\n",
      "epoch: 7\n",
      "予測ラベル(y_hat_1): 0.551 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.644 正解ラベル(y_2): 0\n",
      "\n",
      "epoch: 8\n",
      "予測ラベル(y_hat_1): 0.560 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.617 正解ラベル(y_2): 0\n",
      "\n",
      "epoch: 9\n",
      "予測ラベル(y_hat_1): 0.569 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.590 正解ラベル(y_2): 0\n",
      "\n",
      "epoch: 10\n",
      "予測ラベル(y_hat_1): 0.578 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.564 正解ラベル(y_2): 0\n",
      "\n",
      "epoch: 11\n",
      "予測ラベル(y_hat_1): 0.587 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.539 正解ラベル(y_2): 0\n",
      "\n",
      "epoch: 12\n",
      "予測ラベル(y_hat_1): 0.596 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.515 正解ラベル(y_2): 0\n",
      "\n",
      "epoch: 13\n",
      "予測ラベル(y_hat_1): 0.605 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.492 正解ラベル(y_2): 0\n",
      "\n",
      "epoch: 14\n",
      "予測ラベル(y_hat_1): 0.614 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.470 正解ラベル(y_2): 0\n",
      "\n",
      "epoch: 15\n",
      "予測ラベル(y_hat_1): 0.622 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.450 正解ラベル(y_2): 0\n",
      "\n",
      "epoch: 16\n",
      "予測ラベル(y_hat_1): 0.631 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.431 正解ラベル(y_2): 0\n",
      "\n",
      "epoch: 17\n",
      "予測ラベル(y_hat_1): 0.640 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.412 正解ラベル(y_2): 0\n",
      "\n",
      "epoch: 18\n",
      "予測ラベル(y_hat_1): 0.648 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.396 正解ラベル(y_2): 0\n",
      "\n",
      "epoch: 19\n",
      "予測ラベル(y_hat_1): 0.656 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.380 正解ラベル(y_2): 0\n",
      "\n",
      "epoch: 20\n",
      "予測ラベル(y_hat_1): 0.664 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.365 正解ラベル(y_2): 0\n",
      "\n",
      "epoch: 21\n",
      "予測ラベル(y_hat_1): 0.672 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.351 正解ラベル(y_2): 0\n",
      "\n",
      "epoch: 22\n",
      "予測ラベル(y_hat_1): 0.680 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.337 正解ラベル(y_2): 0\n",
      "\n",
      "epoch: 23\n",
      "予測ラベル(y_hat_1): 0.687 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.325 正解ラベル(y_2): 0\n",
      "\n",
      "epoch: 24\n",
      "予測ラベル(y_hat_1): 0.695 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.313 正解ラベル(y_2): 0\n",
      "\n",
      "epoch: 25\n",
      "予測ラベル(y_hat_1): 0.702 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.302 正解ラベル(y_2): 0\n",
      "\n",
      "epoch: 26\n",
      "予測ラベル(y_hat_1): 0.709 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.292 正解ラベル(y_2): 0\n",
      "\n",
      "epoch: 27\n",
      "予測ラベル(y_hat_1): 0.715 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.282 正解ラベル(y_2): 0\n",
      "\n",
      "epoch: 28\n",
      "予測ラベル(y_hat_1): 0.722 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.273 正解ラベル(y_2): 0\n",
      "\n",
      "epoch: 29\n",
      "予測ラベル(y_hat_1): 0.728 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.265 正解ラベル(y_2): 0\n",
      "\n",
      "epoch: 30\n",
      "予測ラベル(y_hat_1): 0.734 正解ラベル(y_1): 1\n",
      "予測ラベル(y_hat_2): 0.256 正解ラベル(y_2): 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(42)\n",
    "# torch.manual_seed(49)\n",
    "\n",
    "\n",
    "# 入力特徴量\n",
    "x_1 = torch.tensor([0.1, 0.5, -0.2, 1.2, 0.3])\n",
    "x_2 = torch.tensor([0.7, -0.2, -0.4, 0.8, -1.0])\n",
    "\n",
    "\n",
    "# 正解ラベル\n",
    "y_1 = 1 \n",
    "y_2 = 0\n",
    "\n",
    "\n",
    "### 初期化 ###\n",
    "\n",
    "# 重み行列Wを初期化\n",
    "W = torch.randn(1, 5, requires_grad=True) # 5x3次元\n",
    "\n",
    "# epoch = 10\n",
    "epoch = 30\n",
    "# learning_rate = 0.05\n",
    "learning_rate = 0.1\n",
    "# learning_rate = 0.01\n",
    "\n",
    "\n",
    "for i in range(epoch):\n",
    "    \n",
    "    print(f\"epoch: {i+1}\")\n",
    "\n",
    "    ### 順伝播 ###\n",
    "\n",
    "    z_1 = W @ x_1\n",
    "    z_2 = W @ x_2\n",
    "    \n",
    "    y_hat_1 = torch.sigmoid(z_1)\n",
    "    y_hat_2 = torch.sigmoid(z_2)\n",
    "\n",
    "    \n",
    "    # print('予測ラベル(y_hat_1):', y_hat_1.item())\n",
    "    # print('予測ラベル(y_hat_2):', y_hat_2.item())\n",
    "    \n",
    "    # print('正解ラベル(y_1):', y_1)\n",
    "    # print('正解ラベル(y_2):', y_2)\n",
    "    \n",
    "    print('予測ラベル(y_hat_1):', f'{y_hat_1.item():0.3f}', '正解ラベル(y_1):', y_1)\n",
    "    print('予測ラベル(y_hat_2):', f'{y_hat_2.item():0.3f}', '正解ラベル(y_2):', y_2)\n",
    "        \n",
    "\n",
    "    ### 逆伝播 ###\n",
    "\n",
    "    # バイナリクロスエントロピーロス\n",
    "    loss_1 = -(y_1 * torch.log(y_hat_1) + (1 - y_1) * torch.log(1 - y_hat_1))\n",
    "    loss_2 = - (y_2 * torch.log(y_hat_2) + (1 - y_2) * torch.log(1 - y_hat_2))\n",
    "    \n",
    "    loss = loss_1 + loss_2\n",
    "    loss.backward() # W.gradに勾配が入る\n",
    "    \n",
    "\n",
    "    # 勾配を使ってパラメータを更新\n",
    "    with torch.no_grad():\n",
    "        W -= learning_rate * W.grad\n",
    "\n",
    "    # 勾配の初期化\n",
    "    W.grad.zero_()\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6590, 0.2424, 0.0986])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# torch.sigmoid(torch.tensor([2.0]))\n",
    "torch.softmax(torch.tensor([2.0, 1.0, 0.1]), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "output: ['0.540', '0.216', '0.196', '0.044', '0.004']\n",
      "予測ラベル(y_hat): 0\n",
      "正解ラベル(y): 2\n",
      "W.grad: tensor([[ 0.5403,  1.0807,  1.6210],\n",
      "        [ 0.2162,  0.4323,  0.6485],\n",
      "        [-0.8044, -1.6088, -2.4132],\n",
      "        [ 0.0444,  0.0888,  0.1331],\n",
      "        [ 0.0035,  0.0070,  0.0105]])\n",
      "b.grad: tensor([ 0.5403,  0.2162, -0.8044,  0.0444,  0.0035])\n",
      "\n",
      "epoch: 2\n",
      "output: ['0.380', '0.194', '0.377', '0.045', '0.004']\n",
      "予測ラベル(y_hat): 0\n",
      "正解ラベル(y): 2\n",
      "W.grad: tensor([[ 0.3800,  0.7600,  1.1400],\n",
      "        [ 0.1939,  0.3877,  0.5816],\n",
      "        [-0.6228, -1.2457, -1.8685],\n",
      "        [ 0.0453,  0.0905,  0.1358],\n",
      "        [ 0.0037,  0.0074,  0.0111]])\n",
      "b.grad: tensor([ 0.3800,  0.1939, -0.6228,  0.0453,  0.0037])\n",
      "\n",
      "epoch: 3\n",
      "output: ['0.259', '0.152', '0.546', '0.040', '0.003']\n",
      "予測ラベル(y_hat): 2\n",
      "正解ラベル(y): 2\n",
      "W.grad: tensor([[ 0.2592,  0.5184,  0.7776],\n",
      "        [ 0.1520,  0.3041,  0.4561],\n",
      "        [-0.4542, -0.9085, -1.3627],\n",
      "        [ 0.0397,  0.0794,  0.1191],\n",
      "        [ 0.0033,  0.0067,  0.0100]])\n",
      "b.grad: tensor([ 0.2592,  0.1520, -0.4542,  0.0397,  0.0033])\n",
      "\n",
      "epoch: 4\n",
      "output: ['0.184', '0.117', '0.662', '0.033', '0.003']\n",
      "予測ラベル(y_hat): 2\n",
      "正解ラベル(y): 2\n",
      "W.grad: tensor([[ 0.1843,  0.3685,  0.5528],\n",
      "        [ 0.1171,  0.2342,  0.3514],\n",
      "        [-0.3375, -0.6750, -1.0125],\n",
      "        [ 0.0333,  0.0665,  0.0998],\n",
      "        [ 0.0029,  0.0057,  0.0086]])\n",
      "b.grad: tensor([ 0.1843,  0.1171, -0.3375,  0.0333,  0.0029])\n",
      "\n",
      "epoch: 5\n",
      "output: ['0.139', '0.093', '0.738', '0.028', '0.002']\n",
      "予測ラベル(y_hat): 2\n",
      "正解ラベル(y): 2\n",
      "W.grad: tensor([[ 0.1388,  0.2775,  0.4163],\n",
      "        [ 0.0928,  0.1855,  0.2783],\n",
      "        [-0.2621, -0.5241, -0.7862],\n",
      "        [ 0.0281,  0.0561,  0.0842],\n",
      "        [ 0.0025,  0.0050,  0.0074]])\n",
      "b.grad: tensor([ 0.1388,  0.0928, -0.2621,  0.0281,  0.0025])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(49)\n",
    "\n",
    "# クラス数\n",
    "class_num = 5\n",
    "\n",
    "# 入力特徴量\n",
    "x = torch.tensor([1.0, 2.0, 3.0]) # 3次元\n",
    "\n",
    "# 正解ラベル\n",
    "y = 2 # クラス2\n",
    "\n",
    "\n",
    "### 初期化 ###\n",
    "\n",
    "# 重み行列Wを初期化\n",
    "W = torch.randn(class_num, len(x), requires_grad=True) # 5x3次元\n",
    "\n",
    "# バイアスbを初期化\n",
    "b = torch.randn(class_num, requires_grad=True) # 5次元\n",
    "\n",
    "\n",
    "epoch = 5\n",
    "learning_rate = 0.05\n",
    "\n",
    "for i in range(epoch):\n",
    "    \n",
    "    print(f\"epoch: {i+1}\")\n",
    "\n",
    "    ### 順伝播 ###\n",
    "\n",
    "    z = W @ x + b # 5次元\n",
    "    output = torch.softmax(z, dim=0) # 5次元\n",
    "\n",
    "    \n",
    "    # 予測ラベル\n",
    "    y_hat = torch.argmax(output)\n",
    "\n",
    "    print('output:', [f\"{out:.3f}\" for out in output] ) \n",
    "\n",
    "    print('予測ラベル(y_hat):', y_hat.item())\n",
    "    print('正解ラベル(y):', y)\n",
    "\n",
    "    ### 逆伝播 ###\n",
    "\n",
    "    loss = - torch.log(output[y]) # 交差エントロピー誤差\n",
    "\n",
    "    loss.backward() # W.grad, b.gradに勾配が入る\n",
    "    \n",
    "    # δL / δo = (o - y) となることを確認\n",
    "    print('W.grad:', W.grad)\n",
    "    print('b.grad:', b.grad)\n",
    "    \n",
    "    \n",
    "    # 勾配を使ってパラメータを更新\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        W -= learning_rate * W.grad\n",
    "        b -= learning_rate * b.grad\n",
    "    \n",
    "    # 勾配の初期化\n",
    "    W.grad.zero_()\n",
    "    b.grad.zero_()\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "output: ['0.133', '0.851', '0.017']\n",
      "予測ラベル(y_hat): 1\n",
      "正解ラベル(y): 2\n",
      "\n",
      "epoch: 2\n",
      "output: ['0.148', '0.830', '0.023']\n",
      "予測ラベル(y_hat): 1\n",
      "正解ラベル(y): 2\n",
      "\n",
      "epoch: 3\n",
      "output: ['0.163', '0.807', '0.031']\n",
      "予測ラベル(y_hat): 1\n",
      "正解ラベル(y): 2\n",
      "\n",
      "epoch: 4\n",
      "output: ['0.177', '0.781', '0.041']\n",
      "予測ラベル(y_hat): 1\n",
      "正解ラベル(y): 2\n",
      "\n",
      "epoch: 5\n",
      "output: ['0.191', '0.754', '0.055']\n",
      "予測ラベル(y_hat): 1\n",
      "正解ラベル(y): 2\n",
      "\n",
      "epoch: 6\n",
      "output: ['0.204', '0.725', '0.072']\n",
      "予測ラベル(y_hat): 1\n",
      "正解ラベル(y): 2\n",
      "\n",
      "epoch: 7\n",
      "output: ['0.214', '0.693', '0.093']\n",
      "予測ラベル(y_hat): 1\n",
      "正解ラベル(y): 2\n",
      "\n",
      "epoch: 8\n",
      "output: ['0.223', '0.659', '0.118']\n",
      "予測ラベル(y_hat): 1\n",
      "正解ラベル(y): 2\n",
      "\n",
      "epoch: 9\n",
      "output: ['0.228', '0.624', '0.148']\n",
      "予測ラベル(y_hat): 1\n",
      "正解ラベル(y): 2\n",
      "\n",
      "epoch: 10\n",
      "output: ['0.231', '0.587', '0.183']\n",
      "予測ラベル(y_hat): 1\n",
      "正解ラベル(y): 2\n",
      "\n",
      "epoch: 11\n",
      "output: ['0.230', '0.549', '0.221']\n",
      "予測ラベル(y_hat): 1\n",
      "正解ラベル(y): 2\n",
      "\n",
      "epoch: 12\n",
      "output: ['0.227', '0.511', '0.262']\n",
      "予測ラベル(y_hat): 1\n",
      "正解ラベル(y): 2\n",
      "\n",
      "epoch: 13\n",
      "output: ['0.222', '0.473', '0.305']\n",
      "予測ラベル(y_hat): 1\n",
      "正解ラベル(y): 2\n",
      "\n",
      "epoch: 14\n",
      "output: ['0.214', '0.437', '0.349']\n",
      "予測ラベル(y_hat): 1\n",
      "正解ラベル(y): 2\n",
      "\n",
      "epoch: 15\n",
      "output: ['0.206', '0.402', '0.392']\n",
      "予測ラベル(y_hat): 1\n",
      "正解ラベル(y): 2\n",
      "\n",
      "epoch: 16\n",
      "output: ['0.196', '0.370', '0.434']\n",
      "予測ラベル(y_hat): 2\n",
      "正解ラベル(y): 2\n",
      "\n",
      "epoch: 17\n",
      "output: ['0.186', '0.340', '0.474']\n",
      "予測ラベル(y_hat): 2\n",
      "正解ラベル(y): 2\n",
      "\n",
      "epoch: 18\n",
      "output: ['0.176', '0.313', '0.511']\n",
      "予測ラベル(y_hat): 2\n",
      "正解ラベル(y): 2\n",
      "\n",
      "epoch: 19\n",
      "output: ['0.166', '0.289', '0.545']\n",
      "予測ラベル(y_hat): 2\n",
      "正解ラベル(y): 2\n",
      "\n",
      "epoch: 20\n",
      "output: ['0.157', '0.266', '0.576']\n",
      "予測ラベル(y_hat): 2\n",
      "正解ラベル(y): 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "# torch.manual_seed(49)\n",
    "\n",
    "# クラス数\n",
    "class_num = 3\n",
    "\n",
    "# 入力特徴量\n",
    "x = torch.tensor([0.1, 0.5, -0.2, 1.2, 0.3])\n",
    "\n",
    "# 正解ラベル\n",
    "y = 2 # クラス2\n",
    "\n",
    "\n",
    "### 初期化 ###\n",
    "\n",
    "# 重み行列Wを初期化\n",
    "W = torch.randn(3, 5, requires_grad=True) # 5x3次元\n",
    "\n",
    "# epoch = 10\n",
    "epoch = 20\n",
    "# learning_rate = 0.05\n",
    "learning_rate = 0.1\n",
    "\n",
    "for i in range(epoch):\n",
    "    \n",
    "    print(f\"epoch: {i+1}\")\n",
    "\n",
    "    ### 順伝播 ###\n",
    "\n",
    "    z = W @ x # 3次元\n",
    "    output = torch.softmax(z, dim=0) # 5次元\n",
    "\n",
    "    \n",
    "    # 予測ラベル\n",
    "    y_hat = torch.argmax(output)\n",
    "\n",
    "    print('output:', [f\"{out:.3f}\" for out in output] ) \n",
    "\n",
    "    print('予測ラベル(y_hat):', y_hat.item())\n",
    "    print('正解ラベル(y):', y)\n",
    "\n",
    "    ### 逆伝播 ###\n",
    "\n",
    "    loss = - torch.log(output[y]) # 交差エントロピー誤差\n",
    "\n",
    "    loss.backward() # W.grad, b.gradに勾配が入る\n",
    "    \n",
    "    # δL / δo = (o - y) となることを確認\n",
    "    # print('W.grad:', W.grad)\n",
    "    # print('b.grad:', b.grad)\n",
    "    \n",
    "    \n",
    "    # 勾配を使ってパラメータを更新\n",
    "    with torch.no_grad():\n",
    "        W -= learning_rate * W.grad\n",
    "\n",
    "    # 勾配の初期化\n",
    "    W.grad.zero_()\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "# torch.manual_seed(49)\n",
    "\n",
    "# クラス数\n",
    "class_num = 3\n",
    "\n",
    "# 入力特徴量\n",
    "x = torch.tensor([0.1, 0.5, -0.2, 1.2, 0.3])\n",
    "\n",
    "# 正解ラベル\n",
    "y = 2 # クラス2\n",
    "\n",
    "\n",
    "### 初期化 ###\n",
    "\n",
    "# 重み行列Wを初期化\n",
    "W = torch.randn(3, 5, requires_grad=True) # 5x3次元\n",
    "\n",
    "# epoch = 10\n",
    "epoch = 20\n",
    "# learning_rate = 0.05\n",
    "learning_rate = 0.1\n",
    "\n",
    "for i in range(epoch):\n",
    "    \n",
    "    print(f\"epoch: {i+1}\")\n",
    "\n",
    "    ### 順伝播 ###\n",
    "\n",
    "    z = W @ x # 3次元\n",
    "    output = torch.softmax(z, dim=0) # 5次元\n",
    "\n",
    "    \n",
    "    # 予測ラベル\n",
    "    y_hat = torch.argmax(output)\n",
    "\n",
    "    print('output:', [f\"{out:.3f}\" for out in output] ) \n",
    "\n",
    "    print('予測ラベル(y_hat):', y_hat.item())\n",
    "    print('正解ラベル(y):', y)\n",
    "\n",
    "    ### 逆伝播 ###\n",
    "\n",
    "    loss = - torch.log(output[y]) # 交差エントロピー誤差\n",
    "\n",
    "    loss.backward() # W.grad, b.gradに勾配が入る\n",
    "    \n",
    "    # δL / δo = (o - y) となることを確認\n",
    "    # print('W.grad:', W.grad)\n",
    "    # print('b.grad:', b.grad)\n",
    "    \n",
    "    \n",
    "    # 勾配を使ってパラメータを更新\n",
    "    with torch.no_grad():\n",
    "        W -= learning_rate * W.grad\n",
    "\n",
    "    # 勾配の初期化\n",
    "    W.grad.zero_()\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package           Version\n",
      "----------------- -------\n",
      "appnope           0.1.3\n",
      "asttokens         2.4.1\n",
      "comm              0.2.1\n",
      "debugpy           1.8.0\n",
      "decorator         5.1.1\n",
      "exceptiongroup    1.2.0\n",
      "executing         2.0.1\n",
      "ipykernel         6.29.0\n",
      "ipython           8.20.0\n",
      "jedi              0.19.1\n",
      "jupyter_client    8.6.0\n",
      "jupyter_core      5.7.1\n",
      "matplotlib-inline 0.1.6\n",
      "nest-asyncio      1.5.9\n",
      "packaging         23.2\n",
      "parso             0.8.3\n",
      "pexpect           4.9.0\n",
      "pip               23.3.2\n",
      "platformdirs      4.1.0\n",
      "prompt-toolkit    3.0.43\n",
      "psutil            5.9.8\n",
      "ptyprocess        0.7.0\n",
      "pure-eval         0.2.2\n",
      "Pygments          2.17.2\n",
      "python-dateutil   2.8.2\n",
      "pyzmq             25.1.2\n",
      "setuptools        69.0.3\n",
      "six               1.16.0\n",
      "stack-data        0.6.3\n",
      "tornado           6.4\n",
      "traitlets         5.14.1\n",
      "wcwidth           0.2.13\n",
      "wheel             0.42.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# メモ\n",
    "\n",
    "# softmaxとcross entropy\n",
    "# sigmoidとbinary cross entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "# torch.manual_seed(49)\n",
    "\n",
    "# クラス数\n",
    "class_num = 3\n",
    "\n",
    "# 入力特徴量\n",
    "x = torch.tensor([0.1, 0.5, -0.2, 1.2, 0.3])\n",
    "\n",
    "# 正解ラベル\n",
    "y = 2 # クラス2\n",
    "\n",
    "\n",
    "### 初期化 ###\n",
    "\n",
    "# 重み行列Wを初期化\n",
    "W = torch.randn(3, 5, requires_grad=True) # 5x3次元\n",
    "\n",
    "# epoch = 10\n",
    "epoch = 20\n",
    "# learning_rate = 0.05\n",
    "learning_rate = 0.1\n",
    "\n",
    "for i in range(epoch):\n",
    "    \n",
    "    print(f\"epoch: {i+1}\")\n",
    "\n",
    "    ### 順伝播 ###\n",
    "\n",
    "    z = W @ x # 3次元\n",
    "    output = torch.softmax(z, dim=0) # 5次元\n",
    "\n",
    "    \n",
    "    # 予測ラベル\n",
    "    y_hat = torch.argmax(output)\n",
    "\n",
    "    print('output:', [f\"{out:.3f}\" for out in output] ) \n",
    "\n",
    "    print('予測ラベル(y_hat):', y_hat.item())\n",
    "    print('正解ラベル(y):', y)\n",
    "\n",
    "    ### 逆伝播 ###\n",
    "\n",
    "    loss = - torch.log(output[y]) # 交差エントロピー誤差\n",
    "\n",
    "    loss.backward() # W.grad, b.gradに勾配が入る\n",
    "    \n",
    "    # δL / δo = (o - y) となることを確認\n",
    "    # print('W.grad:', W.grad)\n",
    "    # print('b.grad:', b.grad)\n",
    "    \n",
    "    \n",
    "    # 勾配を使ってパラメータを更新\n",
    "    with torch.no_grad():\n",
    "        W -= learning_rate * W.grad\n",
    "\n",
    "    # 勾配の初期化\n",
    "    W.grad.zero_()\n",
    "    \n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
